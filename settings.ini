[file]
# column name
text_col_name = sentence
label_col_name = label

# all class name
class_names = [0, 1]

# csv file with head name ["sentence", "label"]
train_file = data/blog_train.csv
test_file = data/blog_test.csv
# csv file with head name ["sentence"]
predict_file = data/blog_test.csv

embedding_file = resources/GoogleNews-vectors-negative300.bin
embedding_size = 300

# dir where trained model will be saved
model_dir = models
# dir where vocab dict file and predict result file will be saved
result_dir = results

[train]
epochs = 10
batch_size = 64
# use gpu or not
use_cuda = true
# learning rate
learning_rate = 1e-3

[process]
# Sequences longer than this will be filtered out, and shorter than this will be padded with PAD.
max_sentence_len = 30
# Vocab num less than this will be dropped out.
min_word_count = 1
# Whether to use lower case.
do_lower_case = true